{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MALIPEDDIJAHNAVI/Multi-Lingual-NER/blob/main/telugu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjPJrFmDrg3h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to the ZIP file\n",
        "zip_file_path = '/content/archive (1) (1).zip'\n",
        "\n",
        "# Specify the name of the CSV file you want to read\n",
        "csv_file_name = 'telugu_ner.csv'\n",
        "\n",
        "# Open the ZIP file and read the specified CSV file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_file:\n",
        "    with zip_file.open(csv_file_name) as csv_file:\n",
        "        data1 = pd.read_csv(csv_file, encoding='UTF-8')\n",
        "\n",
        "# Display the first 10 rows of the DataFrame\n",
        "data1.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "552t3xXnsnjX",
        "outputId": "efda3f16-707a-4a0e-c147-bba2883c4184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  tokens tags\n",
              "0   పిన్   NN\n",
              "1   కోడ్   NN\n",
              "2     నం   NN\n",
              "3      .  SYM\n",
              "4   పిన్   NN\n",
              "5   కోడ్   NN\n",
              "6    521   QC\n",
              "7    185   QC\n",
              "8      .  SYM\n",
              "9      ఆ  DEM"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf082b50-6b7c-4d4f-801b-6d5ec2a3e926\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>పిన్</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>కోడ్</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>నం</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>.</td>\n",
              "      <td>SYM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>పిన్</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>కోడ్</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>521</td>\n",
              "      <td>QC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>185</td>\n",
              "      <td>QC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>SYM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ఆ</td>\n",
              "      <td>DEM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf082b50-6b7c-4d4f-801b-6d5ec2a3e926')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf082b50-6b7c-4d4f-801b-6d5ec2a3e926 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf082b50-6b7c-4d4f-801b-6d5ec2a3e926');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13b418ec-5666-4c66-893b-df12747e8b6f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13b418ec-5666-4c66-893b-df12747e8b6f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13b418ec-5666-4c66-893b-df12747e8b6f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INXybqnys3oB",
        "outputId": "b3a99407-9771-4163-bc7a-9ca08ce75892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tokens    0\n",
              "tags      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique Words in corpus:\",data1['tokens'].nunique())\n",
        "print(\"Unique Tag in corpus:\",data1['tags'].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aZhpitZs-0Z",
        "outputId": "320b8b4b-e48c-45df-feb9-2219498540c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Words in corpus: 51628\n",
            "Unique Tag in corpus: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data1.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_GD19cZtBX5",
        "outputId": "4c5889e9-4c02-424a-b5ed-b389995793be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tokens', 'tags'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(set(data1['tokens'].values))\n",
        "words.append(\"ENDPAD\")\n",
        "num_words = len(words)\n",
        "tags = list(set(data1['tags'].values))\n",
        "num_tags = len(tags)\n",
        "num_words,num_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVfE89T8tFm0",
        "outputId": "212a1399-a715-4c6b-9510-83b7f641197f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51629, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'Tag' is the column containing tags in your DataFrame\n",
        "tags = list(data1['tags'].values)\n",
        "tags.append(\"ENDPAD\")\n",
        "\n",
        "num_tags = data1['tags'].nunique()  # Number of unique tags excluding 'ENDPAD'\n",
        "tag_values = data1['tags'].unique()  # Unique tag values excluding 'ENDPAD'\n",
        "\n",
        "# Filter out 'ENDPAD' if it exists\n",
        "tag_values = [tag for tag in tag_values if tag != 'ENDPAD']\n",
        "\n",
        "print(\"Number of Tags:\", num_tags)\n",
        "print(\"Tag Values (excluding 'ENDPAD'):\", tag_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmRUOq84tL1Z",
        "outputId": "0916096b-da87-47a5-99ea-6bdea7ae8c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tags: 22\n",
            "Tag Values (excluding 'ENDPAD'): ['NN', 'SYM', 'QC', 'DEM', 'NNP', 'PSP', 'VM', 'JJ', 'NST', 'PRP', 'RB', 'CC', 'WQ', 'QO', 'UT', 'QF', 'INTF', 'CL', 'RP', 'RDP', 'UNK', 'INJ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'Tag' is the column containing tags in your DataFrame\n",
        "tags = list(data1['tags'].values)\n",
        "tags.append(\"ENDPAD\")\n",
        "\n",
        "# Count the occurrences of each tag\n",
        "tag_counts = pd.Series(tags).value_counts()\n",
        "\n",
        "# Remove the count for 'ENDPAD' if it exists\n",
        "tag_counts = tag_counts.drop('ENDPAD', errors='ignore')\n",
        "\n",
        "# Print the total number of tags\n",
        "total_tags = tag_counts.sum()\n",
        "print(\"Total Number of Tags:\", total_tags)\n",
        "\n",
        "# Print the tag counts\n",
        "print(\"Tag Counts:\")\n",
        "print(tag_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZbEM9xCtPmN",
        "outputId": "9088bfda-9a11-4607-b801-9c788767bf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Tags: 259458\n",
            "Tag Counts:\n",
            "NN      116011\n",
            "SYM      41754\n",
            "VM       30284\n",
            "NNP      23383\n",
            "QC       11379\n",
            "PRP       6654\n",
            "PSP       6127\n",
            "JJ        5858\n",
            "RB        5119\n",
            "NST       3184\n",
            "CC        3075\n",
            "DEM       2832\n",
            "UT         938\n",
            "INTF       629\n",
            "RP         606\n",
            "QF         597\n",
            "WQ         517\n",
            "QO         303\n",
            "CL         171\n",
            "RDP         18\n",
            "UNK         10\n",
            "INJ          9\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame has 'name' and 'tag' columns\n",
        "train_data = []\n",
        "\n",
        "for index, row in data1.iterrows():\n",
        "    text = row['tokens']\n",
        "    entities = {'entities': []}\n",
        "\n",
        "    # 'tag' column is assumed to contain entity labels like 'B-PER', 'I-LOC', etc.\n",
        "    tags = row['tags']\n",
        "\n",
        "    start = None\n",
        "    for i, tag in enumerate(tags):\n",
        "        if tag.startswith('B-'):\n",
        "            if start is not None:\n",
        "                entities['entities'].append((start, i, tags[i-1][2:]))\n",
        "            start = i\n",
        "        elif tag.startswith('I-'):\n",
        "            continue\n",
        "        else:  # O tag or other\n",
        "            if start is not None:\n",
        "                entities['entities'].append((start, i, tags[i-1][2:]))\n",
        "            start = None\n",
        "\n",
        "    train_data.append((text, entities))"
      ],
      "metadata": {
        "id": "_XzMCFhKtSmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download xx_ent_wiki_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huq2V_LWtZHN",
        "outputId": "0abf2668-42df-45a3-d5bc-dc0aaad5bc87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-16 13:46:19.798508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:46:19.798567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:46:19.799908: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:46:21.014381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting xx-ent-wiki-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.6.0/xx_ent_wiki_sm-3.6.0-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from xx-ent-wiki-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->xx-ent-wiki-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: xx-ent-wiki-sm\n",
            "Successfully installed xx-ent-wiki-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blg2LGgEtdQH",
        "outputId": "e23d4180-4668-4359-de69-31dd696a87cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-xUiiUUthDD",
        "outputId": "955eb1cc-fceb-42a3-a2d7-d69b675896c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-16 13:46:54.967413: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-16 13:46:54.967481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-16 13:46:54.968858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-16 13:46:56.314696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the small multilingual spaCy model\n",
        "nlp = spacy.load(\"xx_ent_wiki_sm\")"
      ],
      "metadata": {
        "id": "0jC1cwRhtpzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the name of the new directory\n",
        "new_directory_name = 'output'\n",
        "\n",
        "# Create the new directory\n",
        "!mkdir $new_directory_name"
      ],
      "metadata": {
        "id": "sVY3_aiZttK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.prefer_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VLG3tQltvX5",
        "outputId": "a2e57997-a736-456b-e258-b2ecfb7fb429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import spacy\n",
        "\n",
        "# Load the spaCy model (replace 'en_core_web_sm' with the appropriate model)\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define the number of training iterations\n",
        "num_iterations = 100  # Adjust this number as needed\n",
        "\n",
        "# Get the ner component of the pipeline\n",
        "ner = nlp.get_pipe(\"ner\")\n",
        "\n",
        "# Prepare and format training data (replace train_data with your actual training data)\n",
        "train_data = [\n",
        "    (\"Your text here\", {\"entities\": [(0, 4, \"LABEL\")]}),\n",
        "    # Add more examples as needed\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "# Train the model\n",
        "for iteration in range(num_iterations):\n",
        "    # Iterate over the training data\n",
        "    for text, annotations in train_data:\n",
        "        # Update the Named Entity Recognition model\n",
        "        example = spacy.training.example.Example.from_dict(nlp.make_doc(text), annotations)\n",
        "        nlp.update([example], drop=0.5)\n",
        "\n",
        "    # Print some information after each iteration\n",
        "    print(f\"Iteration {iteration + 1} completed.\")\n",
        "\n",
        "# Save the trained model to a file\n",
        "nlp.to_disk(\"output_model\")\n",
        "print(\"Training completed. Model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CMUUd1dtzqo",
        "outputId": "beba86a5-43b2-4e6a-9a67-e9046d4ac2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 completed.\n",
            "Iteration 2 completed.\n",
            "Iteration 3 completed.\n",
            "Iteration 4 completed.\n",
            "Iteration 5 completed.\n",
            "Iteration 6 completed.\n",
            "Iteration 7 completed.\n",
            "Iteration 8 completed.\n",
            "Iteration 9 completed.\n",
            "Iteration 10 completed.\n",
            "Iteration 11 completed.\n",
            "Iteration 12 completed.\n",
            "Iteration 13 completed.\n",
            "Iteration 14 completed.\n",
            "Iteration 15 completed.\n",
            "Iteration 16 completed.\n",
            "Iteration 17 completed.\n",
            "Iteration 18 completed.\n",
            "Iteration 19 completed.\n",
            "Iteration 20 completed.\n",
            "Iteration 21 completed.\n",
            "Iteration 22 completed.\n",
            "Iteration 23 completed.\n",
            "Iteration 24 completed.\n",
            "Iteration 25 completed.\n",
            "Iteration 26 completed.\n",
            "Iteration 27 completed.\n",
            "Iteration 28 completed.\n",
            "Iteration 29 completed.\n",
            "Iteration 30 completed.\n",
            "Iteration 31 completed.\n",
            "Iteration 32 completed.\n",
            "Iteration 33 completed.\n",
            "Iteration 34 completed.\n",
            "Iteration 35 completed.\n",
            "Iteration 36 completed.\n",
            "Iteration 37 completed.\n",
            "Iteration 38 completed.\n",
            "Iteration 39 completed.\n",
            "Iteration 40 completed.\n",
            "Iteration 41 completed.\n",
            "Iteration 42 completed.\n",
            "Iteration 43 completed.\n",
            "Iteration 44 completed.\n",
            "Iteration 45 completed.\n",
            "Iteration 46 completed.\n",
            "Iteration 47 completed.\n",
            "Iteration 48 completed.\n",
            "Iteration 49 completed.\n",
            "Iteration 50 completed.\n",
            "Iteration 51 completed.\n",
            "Iteration 52 completed.\n",
            "Iteration 53 completed.\n",
            "Iteration 54 completed.\n",
            "Iteration 55 completed.\n",
            "Iteration 56 completed.\n",
            "Iteration 57 completed.\n",
            "Iteration 58 completed.\n",
            "Iteration 59 completed.\n",
            "Iteration 60 completed.\n",
            "Iteration 61 completed.\n",
            "Iteration 62 completed.\n",
            "Iteration 63 completed.\n",
            "Iteration 64 completed.\n",
            "Iteration 65 completed.\n",
            "Iteration 66 completed.\n",
            "Iteration 67 completed.\n",
            "Iteration 68 completed.\n",
            "Iteration 69 completed.\n",
            "Iteration 70 completed.\n",
            "Iteration 71 completed.\n",
            "Iteration 72 completed.\n",
            "Iteration 73 completed.\n",
            "Iteration 74 completed.\n",
            "Iteration 75 completed.\n",
            "Iteration 76 completed.\n",
            "Iteration 77 completed.\n",
            "Iteration 78 completed.\n",
            "Iteration 79 completed.\n",
            "Iteration 80 completed.\n",
            "Iteration 81 completed.\n",
            "Iteration 82 completed.\n",
            "Iteration 83 completed.\n",
            "Iteration 84 completed.\n",
            "Iteration 85 completed.\n",
            "Iteration 86 completed.\n",
            "Iteration 87 completed.\n",
            "Iteration 88 completed.\n",
            "Iteration 89 completed.\n",
            "Iteration 90 completed.\n",
            "Iteration 91 completed.\n",
            "Iteration 92 completed.\n",
            "Iteration 93 completed.\n",
            "Iteration 94 completed.\n",
            "Iteration 95 completed.\n",
            "Iteration 96 completed.\n",
            "Iteration 97 completed.\n",
            "Iteration 98 completed.\n",
            "Iteration 99 completed.\n",
            "Iteration 100 completed.\n",
            "Training completed. Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model from disk\n",
        "nlp = spacy.load(\"output_model\")\n",
        "\n",
        "# Test the trained model on new text\n",
        "test_text = \"Your test text here\"\n",
        "doc = nlp(test_text)\n",
        "\n",
        "# Print recognized entities and their labels\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC5d-uLFt87Q",
        "outputId": "44ad89c3-a158-4f58-a610-9ae5075b3c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entity: Your, Label: LABEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\"\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "id": "1vxsdgI7t_nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "9ertpTs2wGGW",
        "outputId": "7d580352-7563-4133-a16d-d423313a1907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.11.17)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17396 sha256=f425f6217299cc66197fa8db5783bd08dd27dbdf448eb410019486358ab95ba5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "idna"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "\n",
        "def translate_telugu_to_english(telugu_text):\n",
        "    # Create a Translator object\n",
        "    translator = Translator()\n",
        "\n",
        "    # Translate telugu text to english\n",
        "    translation = translator.translate(telugu_text, src='te', dest='en')\n",
        "\n",
        "    # Return the translated text\n",
        "    return translation.text\n",
        "\n",
        "# Example telugu text\n",
        "telugu_text=\"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\"\n",
        "\n",
        "\n",
        "# Translate Telugu to english\n",
        "english_translation = translate_telugu_to_english(telugu_text)\n",
        "\n",
        "# Print the results\n",
        "print(\"telugu:\", telugu_text)\n",
        "print(\"English Translation:\", english_translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItaKkfes0kmn",
        "outputId": "c291eb2b-de71-4e50-ed6e-d61d6eb3203a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "telugu: ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\n",
            "English Translation: The Bharatiya Janata Party won this election.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install indicnlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Keq0kyJp2Ipe",
        "outputId": "2a516d33-dca2-4bfe-a1bd-9c7cf4cd2a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indicnlp\n",
            "  Downloading indicnlp-0.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: indicnlp\n",
            "Successfully installed indicnlp-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtJpMXPR2WHp",
        "outputId": "1adbaa53-e591-4ed1-dbba-6c846aa27368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
        "\n",
        "# Function to tokenize Telugu text using indicnlp\n",
        "def tokenize_telugu(text):\n",
        "    sentences = sentence_tokenize.sentence_split(text, lang='te')\n",
        "    tokens = [indic_tokenize.trivial_tokenize(sentence) for sentence in sentences]\n",
        "    return [token for sentence_tokens in tokens for token in sentence_tokens]\n",
        "\n",
        "# Function to perform named entity recognition (NER) on Telugu text\n",
        "def recognize_entities_telugu(telugu_text):\n",
        "    # Translate Telugu to English\n",
        "    english_translation = translate_telugu_to_english(telugu_text)\n",
        "\n",
        "    # Tokenize Telugu text\n",
        "    telugu_tokens = tokenize_telugu(telugu_text)\n",
        "    english_tokens = tokenize_telugu(english_translation)\n",
        "\n",
        "    # Create a spaCy Doc object for English tokens\n",
        "    doc = Doc(nlp.vocab, words=english_tokens)\n",
        "\n",
        "    # Run spaCy NER pipeline\n",
        "    nlp.get_pipe(\"ner\")(doc)\n",
        "\n",
        "    # Extract named entities\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "# Example Telugu text\n",
        "telugu_text = \"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\"\n",
        "\n",
        "# Load English spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Recognize entities in Telugu text\n",
        "telugu_entities = recognize_entities_telugu(telugu_text)\n",
        "\n",
        "# Print the results\n",
        "print(\"Telugu:\", telugu_text)\n",
        "print(\"Recognized Entities:\", telugu_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "PPku3XC_1x0E",
        "outputId": "28e4447c-20b3-433c-b308-dc61865d37d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0825d21a6418>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mindicnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindic_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Function to tokenize Telugu text using indicnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'indicnlp.tokenize'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import random  # Add this line to import the random module\n",
        "\n",
        "# Load a blank Telugu spaCy model\n",
        "nlp = spacy.blank(\"te\")\n",
        "\n",
        "# Add NER labels for your entities\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "ner.add_label(\"OBJECT\")\n",
        "ner.add_label(\"LOCATION\")\n",
        "# Add other labels as needed\n",
        "\n",
        "# Prepare training data\n",
        "train_data = [\n",
        "    (\"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\", {\"entities\": [(13, 31, \"OBJECT\"), (35, 43, \"LOCATION\")]}),\n",
        "    # Add more examples\n",
        "]\n",
        "\n",
        "# Convert training data to spaCy format\n",
        "examples = []\n",
        "for text, annot in train_data:\n",
        "    example = Example.from_dict(nlp.make_doc(text), annot)\n",
        "    examples.append(example)\n",
        "\n",
        "# Train the NER model\n",
        "nlp.begin_training()\n",
        "for epoch in range(10):\n",
        "    # Shuffle examples for each epoch\n",
        "    random.shuffle(examples)\n",
        "    # Update the model with training data\n",
        "    for example in examples:\n",
        "        nlp.update([example], drop=0.5, losses={})\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"/content/output\")\n"
      ],
      "metadata": {
        "id": "Z0iZd_i55BDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the trained Telugu spaCy model\n",
        "nlp = spacy.load(\"/content/output\")  # Replace with the actual path to your trained model\n",
        "\n",
        "# Telugu sentence\n",
        "telugu_sentence = \"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\"\n",
        "\n",
        "# Process the sentence with the NER model\n",
        "doc = nlp(telugu_sentence)\n",
        "\n",
        "# Print recognized entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "id": "H0xyEjwc6Edu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the sentence with the NER model and print all entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}, Confidence: {ent.confidence}\")\n",
        "for token in doc:\n",
        "    print(f\"Token: {token.text}, POS: {token.pos_}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bavwXEQ06TS6",
        "outputId": "2b744437-9dcf-44bd-fb81-dd3afa941765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: ఈ, POS: \n",
            "Token: ఎన్నికల్లో, POS: \n",
            "Token: భారతీయ, POS: \n",
            "Token: జనతా, POS: \n",
            "Token: పార్టీ, POS: \n",
            "Token: విజయం, POS: \n",
            "Token: సాధించింది, POS: \n",
            "Token: ., POS: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training.example import Example\n",
        "import random\n",
        "\n",
        "# Load a blank Telugu spaCy model\n",
        "nlp = spacy.blank(\"te\")\n",
        "\n",
        "# Add NER labels for your entities\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "ner.add_label(\"OBJECT\")\n",
        "ner.add_label(\"LOCATION\")\n",
        "# Add other labels as needed\n",
        "\n",
        "# Prepare training data\n",
        "train_data = [\n",
        "    (\"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\", {\"entities\": [(13, 31, \"OBJECT\"), (35, 43, \"LOCATION\")]}),\n",
        "    # Add more examples\n",
        "]\n",
        "\n",
        "# Convert training data to spaCy format\n",
        "examples = []\n",
        "for text, annot in train_data:\n",
        "    example = Example.from_dict(nlp.make_doc(text), annot)\n",
        "    examples.append(example)\n",
        "\n",
        "# Train the NER model\n",
        "nlp.begin_training()\n",
        "for epoch in range(10):\n",
        "    # Shuffle examples for each epoch\n",
        "    random.shuffle(examples)\n",
        "    # Update the model with training data\n",
        "    for example in examples:\n",
        "        nlp.update([example], drop=0.5, losses={})\n",
        "\n",
        "# Save the trained model\n",
        "nlp.to_disk(\"/content/output\")\n",
        "\n",
        "# Load the trained model\n",
        "nlp_loaded = spacy.load(\"/content/output\")\n",
        "\n",
        "# Test the model with a Telugu sentence\n",
        "telugu_sentence = \"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\"\n",
        "doc = nlp_loaded(telugu_sentence)\n",
        "\n",
        "# Print recognized entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "id": "HmNfziyb6pdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "nlp_loaded = spacy.load(\"/content/output\")\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "# Test the model with a Telugu sentence\n",
        "telugu_sentence = \"ఈ ఎన్నికల్లో భారతీయ జనతా పార్టీ విజయం సాధించింది.\"\n",
        "doc = nlp_loaded(telugu_sentence)\n",
        "\n",
        "# Print recognized entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Entity: {ent.text}, Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5s-7qnn8P3p",
        "outputId": "a11dbc8c-31ce-4d55-cd62-73e3e3d3de65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully\n"
          ]
        }
      ]
    }
  ]
}